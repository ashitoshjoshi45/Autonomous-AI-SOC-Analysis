#Dynamic Server Telemetry: These logs are automatically generated by the log_generator.py script to simulate real-world SSH traffic.
#Security Event Simulation: The data includes a mix of successful authorized logins and malicious failed "brute-force" attempts.
#AI Training Data: This raw log file serves as the input for the Autonomous AI Analyst to detect and respond to security threats.


import time
import re
import subprocess
import google.generativeai as genai
from colorama import Fore, Style, init

# --- CONFIGURATION ---
API_KEY = "YOUR_API_KEY_HERE"  # <--- PASTE YOUR KEY HERE
LOG_FILE = "server_logs.txt"
REAL_BLOCKING = False  # Set to True only if running on a test VM!

# Initialize
init(autoreset=True)
genai.configure(api_key=API_KEY)
model = genai.GenerativeModel('gemini-1.5-flash')

# Compile Regex for IP extraction (Speed optimization)
ip_pattern = re.compile(r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})')

def block_ip(ip_address):
    """
    Executes the system command to block an IP.
    Supports Linux (iptables) and Windows (netsh).
    """
    print(Fore.RED + f"\n[!!!] INITIATING BLOCK PROTOCOL FOR IP: {ip_address}")
    
    if REAL_BLOCKING:
        # Detect OS (Simplified for demo)
        import platform
        os_name = platform.system()
        
        try:
            if os_name == "Linux":
                # The actual Linux command to drop packets
                cmd = f"sudo iptables -A INPUT -s {ip_address} -j DROP"
                subprocess.run(cmd, shell=True, check=True)
                print(Fore.RED + f"    [+] Linux Firewall Rule Applied Successfully.")
                
            elif os_name == "Windows":
                # The actual Windows command
                cmd = f"netsh advfirewall firewall add rule name=\"Block {ip_address}\" dir=in action=block remoteip={ip_address}"
                subprocess.run(cmd, shell=True, check=True)
                print(Fore.RED + f"    [+] Windows Firewall Rule Applied Successfully.")
                
        except Exception as e:
            print(Fore.YELLOW + f"    [-] Failed to apply rule: {e}")
    else:
        # SIMULATION MODE (Safe for personal laptops)
        print(Fore.YELLOW + f"    [SIMULATION] command: sudo iptables -A INPUT -s {ip_address} -j DROP")
        print(Fore.YELLOW + f"    [SIMULATION] IP {ip_address} has been virtually blocked.")

def analyze_log(log_line):
    """
    Asks Gemini to analyze the log and return a strict verdict.
    """
    prompt = f"""
    Analyze this log entry for security threats.
    Log: "{log_line}"
    
    Respond with ONLY one of these two words:
    BLOCK (if it is a malicious attack like brute force)
    PASS (if it is safe or just an error)
    """
    
    try:
        response = model.generate_content(prompt)
        verdict = response.text.strip().upper()
        # Clean up any extra text the AI might add
        if "BLOCK" in verdict: return "BLOCK"
        return "PASS"
    except Exception as e:
        return "PASS" # Fail open (safe)

def monitor_logs():
    print(Fore.CYAN + "[*] Autonomous AI Security Agent v2.0 Started...")
    print(Fore.CYAN + "[*] Monitoring for Threats...")

    # Open the file and go to the end
    with open(LOG_FILE, "r") as f:
        f.seek(0, 2)
        
        while True:
            line = f.readline()
            if not line:
                time.sleep(1)
                continue
                
            # Extract IP from the log line
            ip_match = ip_pattern.search(line)
            if not ip_match:
                continue # Skip lines without IPs
                
            ip_address = ip_match.group(1)
            
            print(f"\n[?] Analyzing: {line.strip()}")
            
            # 1. Ask the AI
            decision = analyze_log(line)
            
            # 2. Act on Decision
            if decision == "BLOCK":
                print(Fore.RED + f"    [!] AI VERDICT: MALICIOUS ATTACK DETECTED.")
                block_ip(ip_address)
            else:
                print(Fore.GREEN + f"    [ok] AI Verdict: Safe.")

if __name__ == "__main__":
    monitor_logs()
